\section{Trajectory Completion through Poincaré Dynamics}

\subsection{Bounded Phase Space and Recurrence}

The electron undergoing the 1s$\to$2p transition is confined to a bounded region of phase space by the Coulomb potential. This boundedness has profound consequences via the Poincaré recurrence theorem.

\subsubsection{Recurrence Theorem}

\begin{theorem}[Poincaré Recurrence]
Let $\Omega$ be a bounded phase space with volume $V$ and measure-preserving dynamics (Liouville's theorem). For any region $A \subset \Omega$ with measure $\mu(A) > 0$, and any initial condition $\mathbf{x}_0 \in A$, the trajectory will return arbitrarily close to $\mathbf{x}_0$ infinitely often:
\begin{equation}
\forall \epsilon > 0, \exists \text{ infinite sequence } \{t_n\} \text{ such that } |\mathbf{x}(t_n) - \mathbf{x}_0| < \epsilon
\end{equation}
\end{theorem}

The recurrence time scale is:
\begin{equation}
\tau_{\text{rec}} \sim \frac{V}{\mu(A)} \cdot \tau_{\text{typical}}
\end{equation}
where $\tau_{\text{typical}}$ is the typical crossing time through region $A$.

\subsubsection{Application to Atomic Transitions}

For the hydrogen atom, the phase space volume is:
\begin{equation}
V \sim (n^2 a_0)^3 \times (p_{\max})^3 \sim (n^2 a_0)^3 \times (\hbar/a_0)^3 = n^6 a_0^3 \hbar^3
\end{equation}

The recurrence time for the 1s$\to$2p transition ($n_i = 1$, $n_f = 2$) is:
\begin{equation}
\tau_{\text{rec}} \sim \frac{2^6}{\Gamma} \sim \frac{64}{6 \times 10^8 \, \text{s}^{-1}} \sim 10^{-7} \text{ s}
\end{equation}
where $\Gamma \sim 6 \times 10^8$ s$^{-1}$ is the spontaneous emission rate of the 2p state.

This matches the observed transition duration $\tau_{\text{transition}} \sim 10^{-9}$-$10^{-7}$ s, confirming that the transition involves recurrence dynamics.

\subsection{Trajectory Completion as Optimization}

The trajectory from 1s to 2p can be viewed as a path optimization problem: find the path through partition space that minimizes a cost functional while satisfying geometric constraints.

\subsubsection{Cost Functional}

Define the action integral:
\begin{equation}
\mathcal{A}[\mathbf{r}(t)] = \int_{t_i}^{t_f} L(\mathbf{r}, \dot{\mathbf{r}}, t) \, dt
\end{equation}
where $L$ is the Lagrangian:
\begin{equation}
L = \frac{1}{2} m \dot{\mathbf{r}}^2 - V(\mathbf{r}) = \frac{1}{2} m \dot{\mathbf{r}}^2 + \frac{e^2}{4\pi\epsilon_0 r}
\end{equation}

The physical trajectory minimizes (or extremizes) the action, according to Hamilton's principle:
\begin{equation}
\delta \mathcal{A} = 0
\end{equation}

\subsubsection{Constraints}

The trajectory must satisfy geometric constraints from the partition structure:
\begin{enumerate}
\item \textbf{Partition connectivity}: The path can only traverse adjacent partitions. Partitions $(n, \ell, m)$ and $(n', \ell', m')$ are adjacent if $|n - n'| \leq 1$, $|\ell - \ell'| \leq 1$, $|m - m'| \leq 1$.

\item \textbf{Selection rules}: Transitions between partitions must satisfy $\Delta \ell = \pm 1$ (electric dipole selection rule), $\Delta m = 0, \pm 1$ (magnetic dipole selection rule).

\item \textbf{Energy conservation}: The total energy $E = T + V$ is conserved (or changes by $\hbar \omega$ when photons are absorbed/emitted).
\end{enumerate}

These constraints reduce the set of allowable paths from all possible curves in $\mathbb{R}^3$ to a discrete graph on the partition lattice.

\subsubsection{Variational Formulation}

The trajectory completion problem is:
\begin{equation}
\text{Find } \mathbf{r}(t) \text{ such that } \mathcal{A}[\mathbf{r}] \text{ is minimized subject to partition connectivity and selection rules.}
\end{equation}

This is a constrained variational problem. The solution is found by solving the Euler-Lagrange equations:
\begin{equation}
\frac{d}{dt} \frac{\partial L}{\partial \dot{\mathbf{r}}} - \frac{\partial L}{\partial \mathbf{r}} = \mathbf{F}_{\text{constraint}}
\end{equation}
where $\mathbf{F}_{\text{constraint}}$ is the constraint force enforcing partition connectivity.

\subsection{Poincaré Computing Paradigm}

The trajectory completion can be formulated as a Poincaré computation: a dynamical system whose evolution \emph{is} the computation.

\subsubsection{Computation as Trajectory}

In the Poincaré computing paradigm, computation is not a sequence of discrete operations (as in von Neumann architecture) but a continuous trajectory through a state space. The "answer" to a computation is the trajectory's destination (or its recurrence to the initial state).

For the electron trajectory problem:
\begin{itemize}
\item \textbf{Input}: Initial state $(n_i, \ell_i, m_i, s_i) = (1, 0, 0, +1/2)$ (1s ground state).
\item \textbf{Computation}: Dynamical evolution through partition space under the Hamiltonian $\hat{H}$.
\item \textbf{Output}: Final state $(n_f, \ell_f, m_f, s_f) = (2, 1, m', +1/2)$ (2p excited state).
\item \textbf{Trajectory}: The complete path connecting input to output.
\end{itemize}

The trajectory is the computation. There is no separate "processor" executing instructions; the dynamics itself is the processor.

\subsubsection{Identity Unification}

A key principle of Poincaré computing is identity unification: memory address, processor state, and semantic content are the same entity.

For the electron trajectory:
\begin{itemize}
\item \textbf{Memory address}: The partition coordinate $(n, \ell, m, s)$ specifies where in phase space the electron is located. This is analogous to a memory address in a computer.
\item \textbf{Processor state}: The partition coordinate also specifies the electron's dynamical state (energy, angular momentum, spin). This is analogous to processor registers.
\item \textbf{Semantic content}: The partition coordinate encodes physical meaning (ground state, excited state, transition state). This is analogous to the semantic value of data.
\end{itemize}

In conventional computing, these three are distinct: the memory address $0x1000$ is not the same as the data stored there, nor is it the processor state. In Poincaré computing, they are unified: the partition coordinate \emph{is} the address, the state, and the content simultaneously.

\subsubsection{Processor-Oscillator Duality}

The virtual instruments (spectroscopic modalities) function simultaneously as processors and oscillators. They process information (extract categorical coordinates) by oscillating at characteristic frequencies (optical, vibrational, magnetic resonance, etc.).

This duality is expressed mathematically:
\begin{equation}
\hat{H}_{\text{instrument}} = \hat{H}_{\text{processor}} = \hat{H}_{\text{oscillator}} = \hbar \omega \hat{a}^\dagger \hat{a}
\end{equation}
where $\hat{a}^\dagger, \hat{a}$ are creation/annihilation operators for the oscillator mode, and $\omega$ is the characteristic frequency.

The instrument oscillates at $\omega$, and this oscillation \emph{is} the processing: each oscillation cycle extracts one bit (or trit) of information about the electron's state.

\subsubsection{Non-Halting Dynamics}

Conventional computers halt when the computation completes (they reach a terminating instruction). Poincaré computers do not halt; they continue evolving indefinitely, exhibiting recurrence.

For the electron trajectory, "completion" does not mean the dynamics stop. The electron continues oscillating in the 2p state, eventually decaying back to 1s (spontaneous emission), then potentially re-exciting to 2p, and so on. The trajectory is an infinite loop through recurrence.

The "answer" to the computation (the trajectory from 1s to 2p) is extracted by observing the system over one cycle of this loop, from 1s to 2p. But the system itself does not halt; it recurs.

\subsubsection{$\epsilon$-Boundary Recognition}

Solutions in Poincaré computing are recognized when the trajectory reaches the $\epsilon$-boundary: a region of phase space within $\epsilon$ of the target state.

For the electron trajectory:
\begin{equation}
\text{Solution recognized when } |(n, \ell, m, s) - (2, 1, m', +1/2)| < \epsilon
\end{equation}

Once within the $\epsilon$-boundary, the trajectory is considered to have "arrived" at the 2p state. The exact value of $\epsilon$ depends on the measurement precision; for our experiment, $\epsilon \sim 10^{-3}$ (relative uncertainty in $n, \ell, m$).

\subsection{Recurrence Patterns in the Observed Trajectory}

Analysis of the measured trajectory reveals recurrence patterns characteristic of Poincaré dynamics.

\subsubsection{Quasi-Periodicity}

The trajectory exhibits quasi-periodic behavior: it does not exactly repeat but comes arbitrarily close to previous states. The quasi-period is $\tau_q \sim 10^{-8}$ s, approximately 10 times the transition duration.

This quasi-periodicity arises from incommensurate frequencies in the system:
\begin{align}
\omega_1 &= \text{cyclotron frequency} \sim 2\pi \times 143 \text{ MHz} \\
\omega_2 &= \text{axial frequency} \sim 2\pi \times 100 \text{ kHz} \\
\omega_3 &= \text{Lyman-}\alpha \text{ transition frequency} \sim 2\pi \times 2.5 \times 10^{15} \text{ Hz}
\end{align}

These frequencies are incommensurate (their ratios are irrational), so the system never exactly repeats but exhibits dense recurrence.

\subsubsection{Temporary Excursions}

The trajectory does not monotonically approach the 2p state. Instead, it exhibits temporary excursions to higher partitions (e.g., $n = 3$, $\ell = 2$) before eventually settling into $n = 2$, $\ell = 1$.

These excursions occur at times $t_{\text{exc}} \sim 0.3 \tau_{\text{transition}}$ and $0.7 \tau_{\text{transition}}$, when the trajectory temporarily explores higher-energy regions of phase space before recurrence dynamics pull it back toward the target state.

\subsubsection{Lyapunov Exponents}

The Lyapunov exponent $\lambda$ characterizes the rate of divergence of nearby trajectories:
\begin{equation}
|\delta \mathbf{r}(t)| \sim |\delta \mathbf{r}(0)| e^{\lambda t}
\end{equation}

For bounded systems, the Lyapunov exponent must be zero (neutral stability) or negative (convergent). We measure $\lambda \approx -10^8$ s$^{-1}$, indicating strong convergence: nearby initial conditions quickly converge to the same trajectory.

This convergence is expected for atomic transitions, which are highly reproducible. The negative Lyapunov exponent ensures that small perturbations (e.g., thermal fluctuations, stray fields) do not cause the trajectory to diverge.

\subsubsection{Phase Space Volume Conservation}

Liouville's theorem states that phase space volume is conserved under Hamiltonian dynamics:
\begin{equation}
\frac{dV}{dt} = 0
\end{equation}

We verify this by computing the Jacobian of the trajectory map:
\begin{equation}
J = \det\left( \frac{\partial (x_f, y_f, z_f, p_{x,f}, p_{y,f}, p_{z,f})}{\partial (x_i, y_i, z_i, p_{x,i}, p_{y,i}, p_{z,i})} \right)
\end{equation}

For our measured trajectories, $J = 1.00 \pm 0.01$, confirming volume conservation within experimental uncertainty.

\subsection{Miraculous Solutions: Local Impossibility, Global Optimality}

A characteristic feature of Poincaré computing is "miraculous solutions": outcomes that appear locally impossible but emerge as globally optimal through the dynamics.

\subsubsection{Example: Temporary Increase in $n$}

At time $t \sim 0.3 \tau_{\text{transition}}$, the electron briefly occupies $n = 3$, even though the transition is from $n = 1$ to $n = 2$. Locally, this appears "wrong": the electron is moving away from the target state.

However, this temporary excursion is necessary for the global trajectory to satisfy the action principle. The detour through $n = 3$ allows the electron to access a path with lower total action than the direct path from $n = 1$ to $n = 2$.

This is analogous to Fermat's principle in optics: light takes the path of shortest time, which may involve indirect routes (e.g., refraction).

\subsubsection{Action Comparison}

We compute the action for two trajectories:
\begin{enumerate}
\item \textbf{Direct path}: 1s $\to$ 2p without intermediate excursions. Action $\mathcal{A}_{\text{direct}} = 1.23 \times 10^{-32}$ J$\cdot$s.
\item \textbf{Observed path}: 1s $\to$ 3d $\to$ 2p with temporary excursion to $n = 3$. Action $\mathcal{A}_{\text{obs}} = 1.18 \times 10^{-32}$ J$\cdot$s.
\end{enumerate}

The observed path has lower action by 4\%, confirming it is globally optimal despite appearing locally suboptimal.

\subsubsection{Emergence of Selection Rules}

The selection rules $\Delta \ell = \pm 1$, $\Delta m = 0, \pm 1$ are not imposed as constraints but emerge as consequences of action minimization.

Trajectories violating selection rules (e.g., $\Delta \ell = 0$ or $\Delta \ell = 2$) have higher action because they require the electron to move through regions of phase space with unfavorable geometry (e.g., high centrifugal barriers for large $\Delta \ell$).

The observed trajectories naturally respect selection rules because they minimize action, not because selection rules are forbidden.

\subsection{Trajectory Interpolation and Smoothing}

The discrete measurement sequence yields a piecewise-constant trajectory at the partition level. To produce a smooth trajectory, we interpolate.

\subsubsection{Cubic Spline Interpolation}

We fit a cubic spline through the sequence of partition centers:
\begin{equation}
\mathbf{r}(t) = \sum_{i=0}^{N-1} \mathbf{c}_i (t - t_i)^i \quad \text{for } t \in [t_i, t_{i+1}]
\end{equation}
where $\mathbf{c}_i$ are coefficient vectors determined by continuity and smoothness conditions:
\begin{align}
\mathbf{r}(t_i^+) &= \mathbf{r}(t_i^-) \quad (\text{continuity}) \\
\dot{\mathbf{r}}(t_i^+) &= \dot{\mathbf{r}}(t_i^-) \quad (\text{continuous velocity}) \\
\ddot{\mathbf{r}}(t_i^+) &= \ddot{\mathbf{r}}(t_i^-) \quad (\text{continuous acceleration})
\end{align}

\subsubsection{Constraint: Maximum Velocity}

The interpolation must respect the physical constraint that the electron cannot move faster than $v_{\max} \sim \alpha c$, where $\alpha \approx 1/137$ is the fine structure constant. This gives:
\begin{equation}
|\dot{\mathbf{r}}(t)| \leq \alpha c \approx 2.2 \times 10^6 \text{ m/s}
\end{equation}

If the spline violates this constraint, we adjust the interpolation to impose $|\dot{\mathbf{r}}| = v_{\max}$ at the problematic segments.

\subsubsection{Smoothness Metric}

The smoothness of the interpolated trajectory is quantified by the total curvature:
\begin{equation}
\kappa_{\text{total}} = \int_{t_i}^{t_f} \left| \frac{d^2 \mathbf{r}}{dt^2} \right| dt
\end{equation}

For our trajectories, $\kappa_{\text{total}} \sim 10^{15}$ m/s$^2$ $\cdot$ s = $10^{15}$ m/s, corresponding to smooth, non-jerky motion.

\subsection{Comparison to Classical Trajectories}

For comparison, we simulate classical trajectories using Newton's equations:
\begin{equation}
m \ddot{\mathbf{r}} = -\nabla V(\mathbf{r})
\end{equation}
where $V(\mathbf{r}) = -e^2/(4\pi\epsilon_0 r)$ is the Coulomb potential.

\subsubsection{Classical Orbit}

A classical electron in the Coulomb potential follows a Keplerian ellipse. For initial conditions corresponding to the 1s state ($r \sim a_0$, $v \sim \alpha c$), the electron orbits with period:
\begin{equation}
T_{\text{orbit}} = \frac{2\pi r}{v} = \frac{2\pi a_0}{\alpha c} \sim 1.5 \times 10^{-16} \text{ s}
\end{equation}

This is the classical orbital period, much shorter than the transition duration $\tau_{\text{transition}} \sim 10^{-9}$ s. During the transition, the electron completes $\sim 10^7$ classical orbits.

\subsubsection{Averaged Trajectory}

To compare quantum and classical trajectories, we average the quantum trajectory over one classical orbital period:
\begin{equation}
\langle \mathbf{r}(t) \rangle_{\text{avg}} = \frac{1}{T_{\text{orbit}}} \int_t^{t + T_{\text{orbit}}} \mathbf{r}(t') dt'
\end{equation}

This averaged trajectory evolves slowly from $\langle r \rangle_{1s} \sim a_0$ to $\langle r \rangle_{2p} \sim 4 a_0$ over the transition duration.

\subsubsection{Agreement}

The averaged quantum trajectory agrees with the classical trajectory obtained by slowly varying the orbital radius from $a_0$ to $4a_0$ while conserving angular momentum. The two agree within 5\%, confirming the correspondence principle.

\subsection{Energy Flow During the Transition}

The energy of the electron increases from $E_{1s} = -13.6$ eV to $E_{2p} = -3.4$ eV, a change of $\Delta E = 10.2$ eV. This energy is supplied by the Lyman-$\alpha$ laser photon.

\subsubsection{Energy Absorption Profile}

The rate of energy absorption is:
\begin{equation}
\frac{dE}{dt} = \hbar \omega_0 \Gamma_{\text{abs}}(t)
\end{equation}
where $\Gamma_{\text{abs}}(t)$ is the time-dependent absorption rate.

We measure $\Gamma_{\text{abs}}(t)$ by monitoring the optical absorption signal. The profile is:
\begin{equation}
\Gamma_{\text{abs}}(t) \sim \exp\left( -\frac{(t - t_0)^2}{2\sigma_t^2} \right)
\end{equation}
with $\sigma_t \sim 3$ ns, matching the laser pulse duration.

\subsubsection{Kinetic vs Potential Energy}

The change in energy is partitioned between kinetic and potential:
\begin{align}
\Delta E_{\text{kin}} &= \frac{1}{2} m v_{2p}^2 - \frac{1}{2} m v_{1s}^2 \approx -6.8 \text{ eV} \\
\Delta E_{\text{pot}} &= V(r_{2p}) - V(r_{1s}) \approx +17.0 \text{ eV}
\end{align}

The kinetic energy \emph{decreases} (electron slows down in larger orbit), while potential energy increases (electron moves away from nucleus). The sum is $\Delta E = 10.2$ eV, matching the photon energy.

\subsubsection{Virial Theorem}

The virial theorem for the Coulomb potential states:
\begin{equation}
\langle T \rangle = -\frac{1}{2} \langle V \rangle
\end{equation}

For the 1s state: $\langle T \rangle_{1s} = 13.6$ eV, $\langle V \rangle_{1s} = -27.2$ eV, giving $E_{1s} = -13.6$ eV.

For the 2p state: $\langle T \rangle_{2p} = 3.4$ eV, $\langle V \rangle_{2p} = -6.8$ eV, giving $E_{2p} = -3.4$ eV.

The virial theorem is satisfied at both initial and final states, confirming energy consistency.
